# DIY Web Scraping Guide for Beautynomy

**Last Updated:** October 19, 2025
**Status:** Complete Guide for Self-Hosted Scraping

---

## üìã **Table of Contents**

1. [Current Status](#current-status)
2. [Why Some Scrapers Fail](#why-some-scrapers-fail)
3. [Enhancement Strategy](#enhancement-strategy)
4. [Implementation Guide](#implementation-guide)
5. [Testing & Debugging](#testing--debugging)
6. [Advanced Techniques](#advanced-techniques)
7. [Legal & Ethical Considerations](#legal--ethical-considerations)
8. [Troubleshooting](#troubleshooting)

---

## üéØ **Current Status**

### What You Have ‚úÖ

**1. Working Scrapers**
- ‚úÖ **Amazon** - HTTP + Cheerio (Works on Render free tier!)
- ‚ö†Ô∏è **Nykaa** - HTTP + Cheerio (40-60% success rate)
- ‚ö†Ô∏è **Flipkart** - HTTP + Cheerio (30-50% success rate)
- ‚ö†Ô∏è **Purplle** - HTTP + Cheerio (20-40% success rate)
- ‚ö†Ô∏è **Tira** - HTTP + Cheerio (20-40% success rate)
- ‚ö†Ô∏è **Sephora** - HTTP + Cheerio (20-40% success rate)

**2. Architecture**
```
User Request
    ‚Üì
scraper-service.js ‚Üí Orchestrates scraping
    ‚Üì
scrapers/index.js ‚Üí Runs all 6 scrapers in parallel
    ‚Üì
Individual scrapers ‚Üí amazon.js, nykaa.js, etc.
    ‚Üì
Cheerio ‚Üí Parses HTML
    ‚Üì
Extract data ‚Üí name, price, image, url
    ‚Üì
Cuelinks ‚Üí Convert to affiliate links
    ‚Üì
MongoDB ‚Üí Save products
```

**3. Current Success Rate**
- Amazon: **90-95%** ‚úÖ
- Nykaa: **20-40%** ‚ö†Ô∏è
- Flipkart: **30-50%** ‚ö†Ô∏è
- Others: **20-40%** ‚ö†Ô∏è

---

## üö´ **Why Some Scrapers Fail**

### 1. **Anti-Bot Detection**

**Problem:**
```
403 Forbidden
Access Denied
Unusual Traffic Detected
```

**Why:**
- Simple HTTP requests don't look like real browsers
- Missing browser-specific headers
- No cookies/session
- Too fast (inhuman speed)
- Same User-Agent every time

**Solution:**
```javascript
// Bad (Gets blocked)
axios.get(url)

// Good (Looks like browser)
axios.get(url, {
  headers: {
    'User-Agent': 'Mozilla/5.0...',
    'Accept': 'text/html...',
    'Accept-Language': 'en-US,en;q=0.9',
    'Referer': 'https://www.nykaa.com/',
    'Sec-Fetch-Dest': 'document',
    // ... 10+ more headers
  }
})
```

### 2. **JavaScript Rendering**

**Problem:**
- Cheerio can only see initial HTML
- Modern sites load products with JavaScript
- Content appears **after** page load

**Example:**
```html
<!-- What server sends (empty) -->
<div id="products"></div>

<!-- What browser sees after JS runs -->
<div id="products">
  <div>Product 1...</div>
  <div>Product 2...</div>
</div>
```

**Cheerio sees:** Empty div
**Browser sees:** Products

**Solution:**
- Use Puppeteer (simulates real browser)
- Or find API endpoints that return JSON

### 3. **Dynamic CSS Classes**

**Problem:**
```javascript
// Today's selector
$('.css-1gc4wt9')

// Tomorrow's selector (after site update)
$('.css-2hd8xk1')  // ‚ùå Broken!
```

**Solution:**
```javascript
// Use multiple fallback selectors
const name = $el.find('.css-1gc4wt9').text() ||
             $el.find('[data-test="title"]').text() ||
             $el.find('h2').text() ||
             $el.find('a').attr('title');
```

### 4. **Rate Limiting**

**Problem:**
```
429 Too Many Requests
```

**Why:**
- Sending too many requests too fast
- Servers have rate limits

**Solution:**
```javascript
// Add delays between requests
await sleep(2000); // Wait 2 seconds
```

---

## üöÄ **Enhancement Strategy**

### **Level 1: Enhanced HTTP Scraping** (FREE)

‚úÖ **Works on Render FREE tier**
‚úÖ **Improves success rate from 20% ‚Üí 60%**

**Techniques:**
1. **Better Headers**
   - Full browser headers
   - User-Agent rotation
   - Proper Referer
   - Sec-Fetch-* headers

2. **Request Management**
   - Retries with exponential backoff
   - Random delays (1-3 seconds)
   - Error handling
   - Timeout handling

3. **Smart Parsing**
   - Multiple fallback selectors
   - Pattern matching
   - Validation

4. **Anti-Detection**
   - Rotate User-Agents
   - Add random delays
   - Limit concurrent requests
   - Session management

### **Level 2: Proxy Rotation** ($10-30/month)

‚ö†Ô∏è **Optional - Only if Level 1 isn't enough**

**Services:**
- ScraperAPI: $49/month (handles everything)
- Bright Data: $15+/month
- Oxylabs: $49+/month

**How it works:**
```
Your Server ‚Üí Proxy Service ‚Üí E-commerce Site
```

Proxy service:
- Rotates IPs automatically
- Handles CAPTCHAs
- Bypasses blocks

### **Level 3: Puppeteer** ($7/month Render Starter)

‚ö†Ô∏è **Required for JS-heavy sites**
‚ö†Ô∏è **Needs Render Starter plan**

**Pros:**
- Real browser (sees JavaScript content)
- 90%+ success rate
- Can handle any website

**Cons:**
- Slower (5-10 seconds per request)
- Higher server cost ($7/month vs free)
- More memory/CPU needed

---

## üíª **Implementation Guide**

### **Step 1: Enhance Existing Scrapers** (FREE)

I've created enhanced utilities for you:

**1. Install Enhanced Helpers:**
```bash
# Already created:
# /server/utils/scraper-helpers.js
```

**2. Update Your Scrapers:**

**Before (basic):**
```javascript
// nykaa.js
const { data } = await axios.get(url, {
  headers: { 'User-Agent': '...' }
});
```

**After (enhanced):**
```javascript
// nykaa-enhanced.js
import { makeRequest, extractPrice, isBlocked } from '../utils/scraper-helpers.js';

const html = await makeRequest(url, {
  platform: 'nykaa',
  maxRetries: 3,
  retryDelay: 3000
});

if (isBlocked(html)) {
  console.log('Blocked by CAPTCHA');
  return [];
}
```

**3. Update scrapers/index.js:**
```javascript
// Add enhanced versions
import scrapeNykaaEnhanced from './nykaa-enhanced.js';

// Use enhanced version
const nykaaResults = await scrapeNykaaEnhanced(productName);
```

### **Step 2: Test Enhanced Scrapers**

```bash
# Test individual platform
curl -X POST http://localhost:5000/api/scrape \
  -H "Content-Type: application/json" \
  -d '{"productName": "lakme lipstick"}'

# Check logs for:
# ‚úÖ Successful scrapes
# ‚ùå 403 errors
# ‚è±Ô∏è  Timeouts
```

### **Step 3: Monitor Success Rate**

```javascript
// Add to scraper-service.js
const stats = {
  nykaa: { success: 0, failed: 0 },
  flipkart: { success: 0, failed: 0 },
  // ...
};

// Track each attempt
if (nykaaResults.length > 0) {
  stats.nykaa.success++;
} else {
  stats.nykaa.failed++;
}

// Log periodically
console.log('Success rates:', {
  nykaa: `${(stats.nykaa.success / (stats.nykaa.success + stats.nykaa.failed) * 100).toFixed(1)}%`,
  // ...
});
```

---

## üß™ **Testing & Debugging**

### **Test Suite**

```bash
# Test all platforms
npm run test:scrapers

# Test specific platform
curl -X POST http://localhost:5000/api/scrape \
  -H "Content-Type: application/json" \
  -d '{"productName": "nykaa matte lipstick"}'
```

### **Debug Checklist**

**If scraper returns 0 products:**

1. **Check network response:**
```javascript
console.log('Response length:', html.length);
console.log('First 500 chars:', html.substring(0, 500));
```

2. **Check for blocks:**
```javascript
if (html.includes('captcha') || html.includes('Access Denied')) {
  console.log('‚ùå BLOCKED!');
}
```

3. **Check selectors:**
```javascript
console.log('Product containers found:', productContainers.length);
console.log('First container HTML:', productContainers.first().html());
```

4. **Check extracted data:**
```javascript
console.log('Name:', name, '| Price:', price, '| URL:', url);
```

### **Common Issues & Fixes**

| Issue | Cause | Fix |
|-------|-------|-----|
| 403 Forbidden | Anti-bot detected | Add better headers, delays, retry |
| 0 products found | CSS selectors changed | Update selectors, use multiple fallbacks |
| Timeout | Slow server | Increase timeout to 20s |
| Invalid prices | Wrong selector | Check price extraction logic |
| Broken URLs | Relative paths | Use `normalizeUrl()` helper |

---

## üî• **Advanced Techniques**

### **1. Find Hidden API Endpoints**

Many sites have JSON APIs that are easier to scrape:

**How to find:**
1. Open site in Chrome
2. Press F12 (DevTools)
3. Go to Network tab
4. Search for a product
5. Look for XHR/Fetch requests returning JSON

**Example (Nykaa):**
```
# Instead of scraping HTML:
https://www.nykaa.com/search?q=lipstick

# Use their API directly:
https://www.nykaa.com/api/search?query=lipstick&format=json
```

**Benefits:**
- No HTML parsing needed
- Faster
- More reliable
- Less likely to be blocked

### **2. Session Management**

Keep session/cookies across requests:

```javascript
import axios from 'axios';

const session = axios.create({
  headers: getBrowserHeaders(),
  withCredentials: true
});

// First request sets cookies
await session.get('https://www.nykaa.com/');

// Subsequent requests use same cookies
await session.get('https://www.nykaa.com/search?q=lipstick');
```

### **3. Respect robots.txt**

```bash
# Check what's allowed:
curl https://www.nykaa.com/robots.txt

# Look for:
# User-agent: *
# Disallow: /checkout
# Crawl-delay: 1
```

Add delays as specified:
```javascript
// If robots.txt says: Crawl-delay: 2
await sleep(2000); // Wait 2 seconds between requests
```

### **4. Error Recovery**

```javascript
try {
  const products = await scrapeNykaa(query);
  if (products.length > 0) {
    return products;
  }

  // Fallback 1: Try enhanced scraper
  return await scrapeNykaaEnhanced(query);

} catch (error) {
  // Fallback 2: Try cached results
  return await getCachedProducts(query);
}
```

---

## ‚öñÔ∏è **Legal & Ethical Considerations**

### **Legal Status in India**

**‚úÖ Generally Legal:**
- Scraping publicly available data
- Personal/research use
- Price comparison (legitimate business)

**‚ö†Ô∏è Gray Area:**
- Commercial use at scale
- Ignoring robots.txt
- Bypassing technical protection measures

**‚ùå Illegal:**
- Scraping private/login-required data
- Scraping personal information (GDPR/DPDPA violations)
- DDoS/overwhelming servers
- Copyright infringement

### **Best Practices**

**1. Be Respectful:**
```javascript
// Good
await sleep(2000); // 2 seconds between requests

// Bad
for (let i = 0; i < 1000; i++) {
  await scrape(); // No delay = DDoS
}
```

**2. Identify Yourself:**
```javascript
headers: {
  'User-Agent': 'BeautynomyBot/1.0 (+https://beautynomy.com/about)'
}
```

**3. Honor robots.txt:**
```
Crawl-delay: 1  // Wait 1 second
Disallow: /checkout  // Don't scrape
```

**4. Don't Scrape Personal Data:**
- ‚ùå User reviews with names
- ‚ùå Email addresses
- ‚ùå Phone numbers
- ‚úÖ Product names, prices (public data)

**5. Cache Results:**
```javascript
// Don't scrape same product every hour
// Cache for 24 hours
if (cached && cacheAge < 24 * 3600 * 1000) {
  return cached;
}
```

### **Beautynomy-Specific Guidelines**

**‚úÖ OK to Scrape:**
- Product names
- Product prices
- Product images (with attribution)
- Product URLs
- Ratings (aggregate numbers)

**‚ùå Don't Scrape:**
- User reviews (personal opinions)
- User names
- Email/phone from reviews
- Private/member-only content

---

## üõ†Ô∏è **Troubleshooting**

### **Problem: All Platforms Returning 0 Products**

**Diagnosis:**
```bash
# Check if server is running
curl http://localhost:5000/

# Check network connectivity
curl https://www.amazon.in/

# Check scrapers directly
node -e "import('./scrapers/amazon.js').then(m => m.default('lipstick').then(console.log))"
```

**Fixes:**
1. Restart server: `npm start`
2. Clear cache: `rm -rf node_modules/.cache`
3. Check internet connection
4. Check if sites are down: https://downdetector.com/

### **Problem: Only Amazon Works**

**Diagnosis:**
- Nykaa/Flipkart have stronger anti-bot measures
- Using basic scrapers without enhancements

**Fix:**
1. Use enhanced scrapers (see Implementation Guide)
2. Add delays between requests
3. Rotate User-Agents
4. Consider Puppeteer (if budget allows)

### **Problem: Scrapers Work Locally but Fail on Render**

**Diagnosis:**
- Render's IP might be blocked
- Different network environment
- Missing dependencies

**Fixes:**
1. Check Render logs: `render logs`
2. Verify all dependencies installed
3. Add more retries for Render environment:
```javascript
const isRender = process.env.RENDER === 'true';
const maxRetries = isRender ? 5 : 3;
```

### **Problem: Getting 403 Errors**

**Fixes:**
1. **Add more headers:**
```javascript
headers: {
  ...getBrowserHeaders(),
  'Sec-CH-UA': '"Chromium";v="120", "Chrome";v="120"',
  'Sec-CH-UA-Mobile': '?0',
  'Sec-CH-UA-Platform': '"macOS"'
}
```

2. **Add delays:**
```javascript
await randomDelay(2000, 5000); // 2-5 seconds
```

3. **Rotate User-Agents:**
```javascript
headers: {
  'User-Agent': getRandomUserAgent()
}
```

4. **Last Resort: Use Proxy**

---

## üìä **Performance Optimization**

### **1. Parallel Scraping**

**Current (Fast):**
```javascript
// All platforms at once
const results = await Promise.allSettled([
  scrapeNykaa(query),
  scrapeAmazon(query),
  scrapeFlipkart(query),
]);
```

**Alternative (Safer):**
```javascript
// One at a time with delays
const results = [];
results.push(await scrapeAmazon(query));
await sleep(1000);
results.push(await scrapeNykaa(query));
await sleep(1000);
results.push(await scrapeFlipkart(query));
```

### **2. Caching**

```javascript
// Cache results for 1 hour
const cache = new Map();

async function scrapeWithCache(platform, query) {
  const key = `${platform}:${query}`;
  const cached = cache.get(key);

  if (cached && Date.now() - cached.time < 3600000) {
    return cached.data;
  }

  const data = await scrapePlatform(platform, query);
  cache.set(key, { data, time: Date.now() });

  return data;
}
```

### **3. Selective Scraping**

```javascript
// Only scrape platforms that are working well
const enabledPlatforms = {
  amazon: true,    // 90% success
  nykaa: false,    // 30% success - disabled
  flipkart: false  // 40% success - disabled
};

if (enabledPlatforms.amazon) {
  results.push(await scrapeAmazon(query));
}
```

---

## üìö **Additional Resources**

### **Learning**
- [Web Scraping with Node.js](https://scrapingant.com/blog/web-scraping-with-nodejs)
- [Cheerio Documentation](https://cheerio.js.org/)
- [Axios Documentation](https://axios-http.com/)

### **Tools**
- [Puppeteer](https://pptr.dev/) - Browser automation
- [Playwright](https://playwright.dev/) - Modern alternative to Puppeteer
- [ScraperAPI](https://www.scraperapi.com/) - Managed scraping service

### **Testing**
- [Postman](https://www.postman.com/) - Test API requests
- [Chrome DevTools](https://developer.chrome.com/docs/devtools/) - Inspect websites

---

## üéØ **Summary**

### **Current State:**
- ‚úÖ Amazon scraper working (90% success)
- ‚ö†Ô∏è Other platforms: 20-40% success
- ‚úÖ Good architecture already in place

### **Recommended Next Steps:**

**Option 1: Enhance HTTP Scrapers (FREE)** ‚≠ê **RECOMMENDED**
1. Use `scraper-helpers.js` utilities
2. Update scrapers with better headers
3. Add retries and delays
4. **Expected result:** 60-70% success rate
5. **Cost:** $0 (works on free tier)

**Option 2: Amazon Only ($0)**
- Keep only Amazon scraper
- Disable others
- 90% success rate on 1 platform
- Simplest, most reliable

**Option 3: Add Puppeteer ($7/month)**
- Install Puppeteer
- Upgrade to Render Starter
- 90%+ success on all platforms
- Slower but very reliable

**Option 4: Use Paid API ($15-99/month)**
- Rainforest API (Amazon only): $15/month
- ScraperAPI (all platforms): $49/month
- Zero maintenance

---

**Questions? Issues?**
- Check Troubleshooting section above
- Review logs for specific error messages
- Test with `curl` commands provided

**Ready to enhance your scrapers? Let's do it!** üöÄ
